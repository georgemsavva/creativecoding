[
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "",
    "text": "The mortality rate in the treatment arm is is 34.9%. In the control arm is is 43.4%.\nThe estimate for treatment effect (risk difference) is -8.5%\nThe 95% confidence interval is -18.2 to +1.2 percentage points. This means that the treatment might plausibly improve mortality by 18.2 or worsen it by 1.2 percentage points.\nBecause the p-value is 0.06, at the confidence interval includes 0 (no treatment effect) the journal report is that there is no significant improvement.\nI would conclude there is a very good chance that the treatment is an improvement on the control, although this isn’t definitively proven, and it doesn’t increase survival by more than 20 percentage points.\nPersonally I would choose the new treatment (all else equal)\nI would do whatever I could to get the new treatment."
  },
  {
    "objectID": "solutions.html#exercise-1",
    "href": "solutions.html#exercise-1",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "",
    "text": "The mortality rate in the treatment arm is is 34.9%. In the control arm is is 43.4%.\nThe estimate for treatment effect (risk difference) is -8.5%\nThe 95% confidence interval is -18.2 to +1.2 percentage points. This means that the treatment might plausibly improve mortality by 18.2 or worsen it by 1.2 percentage points.\nBecause the p-value is 0.06, at the confidence interval includes 0 (no treatment effect) the journal report is that there is no significant improvement.\nI would conclude there is a very good chance that the treatment is an improvement on the control, although this isn’t definitively proven, and it doesn’t increase survival by more than 20 percentage points.\nPersonally I would choose the new treatment (all else equal)\nI would do whatever I could to get the new treatment."
  },
  {
    "objectID": "solutions.html#exercise-2",
    "href": "solutions.html#exercise-2",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 2",
    "text": "Exercise 2\nIf we recruit 10 patients and two have stool in their virus, then our estimate for the prevalence of virus in stool can be calculated by R as follows:\n\nbinom.test(x=2,n=10)\n\n\n    Exact binomial test\n\ndata:  2 and 10\nnumber of successes = 2, number of trials = 10, p-value = 0.1094\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.02521073 0.55609546\nsample estimates:\nprobability of success \n                   0.2 \n\n\nThe confidence interval is 0.03 (3%) to 0.56 (56%). So this is the plausible range for the true value given the data.\nWith 100 participants, if we observe 20 then our calculation would be calculated with:\n\nbinom.test(x=20,n=100)\n\n\n    Exact binomial test\n\ndata:  20 and 100\nnumber of successes = 20, number of trials = 100, p-value = 1.116e-09\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.1266556 0.2918427\nsample estimates:\nprobability of success \n                   0.2 \n\n\nSo 13% to 30%.\nWe can tweak the sample size until we have a confidence interval that is 5% either side of the truth. N=250 gets us pretty close:\n\nN=250\nbinom.test(x=N*0.2 , n = N)\n\n\n    Exact binomial test\n\ndata:  N * 0.2 and N\nnumber of successes = 50, number of trials = 250, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.1522402 0.2550261\nsample estimates:\nprobability of success \n                   0.2 \n\n\nNote this is the number of samples that we need data for, we might find that 10% or so of the participants do not give us valid data.\nWe can see that the sample size needed depends enormously on the precision we need for the estimate, and in this case we need to have some idea of what the answer is going to be."
  },
  {
    "objectID": "solutions.html#exercise-3",
    "href": "solutions.html#exercise-3",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 3:",
    "text": "Exercise 3:\nHere we can use the app to simulate some data\nhttps://georgemsavva.shinyapps.io/powerSimulator/\nor we can do it in code:\n\n# Make some assumptions\ncontrolMean = 500\ntreatmentEffect = -20\nstandardDeviation = 60\n\n# set our sample size\nN = 10\n\n# Simulate some data\ncontrolResults = rnorm(N , mean=controlMean, sd=standardDeviation)\ntestResults    = rnorm(N , mean=controlMean+treatmentEffect, sd=standardDeviation)\n\n# Plot the data\nplot(y=c(controlResults , testResults), \n     x=factor(rep(c(\"Control\", \"Test\"), each=N)), \n     ylab=\"iAUC\", xlab=\"Group\")\n\npoints(y=c(controlResults , testResults), \n       x=factor(rep(c(\"Control\", \"Test\"), each=N)))\n\n\n\n\n\n\n\n# Run a t-test\nt.test(controlResults, testResults)\n\n\n    Welch Two Sample t-test\n\ndata:  controlResults and testResults\nt = -0.27587, df = 16.529, p-value = 0.7861\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -68.60823  52.77155\nsample estimates:\nmean of x mean of y \n 452.6648  460.5831 \n\n\nIf we only had one person per group we couldn’t conclude anything, since we wouldn’t know if the difference is due to the person or due to the treatment.\nAs we get more samples we can become more sure that any differences we see are because of the treatment.\nThe estimate for effect will become more precise as we increase the sample size.\nUsing the app I can show that the width of the confidence interval will be about 40 units if there are approximately 60 participants in each group.\nIf we simulate more than one experiment, we can see that the p-value varies every time we run it. In reality we’ll only run one experiment, and we want to make sure that the probability of getting a p-value of less than 0.05 is high (given the assumption that our effect is real).\nIf we assume the true effect is 20 units, then to get 80% of trials significant we need about 150 participants per group."
  },
  {
    "objectID": "solutions.html#exercise-4",
    "href": "solutions.html#exercise-4",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 4",
    "text": "Exercise 4\nA study has a power of 80% if, given that a true effect exists, there is an 80% chance it will detect it as a significant difference.\nThis clearly depends on what the magnitude of the real effect is, how much variation there is etc.\nWe don’t learn a lot from studies that are underpowered. In these cases it might be better to look at the effect sizes and confidence intervals, since conclusions based on p-values will be very unreliable.\nA study is underpowered if it is too small to be able to detect meaningul effect sizes. For example, the ANDROMEDA-SHOCK study we looked at wasn’t able to detect an effect size of 12.5% as statistically significant. So it was underpowered for effects of that size or smaller."
  },
  {
    "objectID": "solutions.html#exercise-5",
    "href": "solutions.html#exercise-5",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe fault is ignoring the risk of errors, particularly false negatives, which because much more likely if the study size is small.\nStatement three should reas “If p&gt;0.05 we don’t have enough evidence to demonstrate an effect” or something like that. It could well be that an effect is present but our study could not detect it."
  },
  {
    "objectID": "solutions.html#exercise-6",
    "href": "solutions.html#exercise-6",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 6",
    "text": "Exercise 6\nTo find the sample size needed (per group) to estimate the precision of the risk difference to +-10 percentage points, we can use the precisely library. If you don’t like code you can use the Shiny app (https://malcolmbarrett.shinyapps.io/precisely/)\n\n# If you don't have the \n#install.packages(\"precisely\")\nlibrary(precisely)\n\nWarning: package 'precisely' was built under R version 4.1.3\n\nn_risk_difference(precision=0.2, \n                  exposed = 0.4,\n                  unexposed = 0.2, \n                  group_ratio = 1)\n\n# A tibble: 1 x 9\n  n_exposed n_unexposed n_total risk_difference precision exposed unexposed\n      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1      154.        154.    307.             0.2       0.2     0.4       0.2\n# i 2 more variables: group_ratio &lt;dbl&gt;, ci &lt;dbl&gt;\n\n\nNow to find the possible precision with 15 patients per group:\n\nprecisely::precision_risk_difference(n_exposed=15, \n                                     exposed=0.4, \n                                     unexposed=0.2,\n                                     group_ratio = 1)\n\n# A tibble: 1 x 9\n  precision risk_difference n_exposed n_unexposed n_total exposed unexposed\n      &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1     0.640             0.2        15          15      30     0.4       0.2\n# i 2 more variables: group_ratio &lt;dbl&gt;, ci &lt;dbl&gt;\n\n\nSo with only 15 per group (a sample size of 30) we would have a confidence interval for the risk difference of 0.64! This is enormous in the context of trying to look for difference in the outcome from 20% to 40% recovery."
  },
  {
    "objectID": "solutions.html#exercise-7",
    "href": "solutions.html#exercise-7",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 7",
    "text": "Exercise 7\nFollowing the pwr.t.test video, we can find the sample size needed to test whether our bread leads to an improvement in iAUC of at least 20 units.\n\nlibrary(pwr)\n\nWarning: package 'pwr' was built under R version 4.1.2\n\npwr.t.test( n=NULL , d = 20/60 , power=0.8 )\n\n\n     Two-sample t test power calculation \n\n              n = 142.2462\n              d = 0.3333333\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nTo find the smallest effect size detectable with 10 participants per group:\n\npwr.t.test( n=10 , d = NULL , power=0.8 )\n\n\n     Two-sample t test power calculation \n\n              n = 10\n              d = 1.324947\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThis gives us a Cohen’s d of 1.3, which would correspond to a smallest detectable difference between treatments of about 78 units (given a standard deviation of 60 units)\n\npwr.t.test( n=100 , d = NULL , power=0.8 )\n\n\n     Two-sample t test power calculation \n\n              n = 100\n              d = 0.3981407\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nWith 100 participants per group we could detect a Cohen’s d of 0.4 or a difference in iAUC of about 24 units.\nNote there is a simple correspondence between the sample size and the Cohen’s d which will translate to every study of this design (simple two group parallel study).\nTo find the power:\n\npwr.t.test( n=10 , d=50/60 , power=NULL)\n\n\n     Two-sample t test power calculation \n\n              n = 10\n              d = 0.8333333\n      sig.level = 0.05\n          power = 0.4223915\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nMaking a power curve is a bit fiddly:\n\n# this line will extract the 'power' part of the output\npower = pwr.t.test( n=10:100 , # we can add a sequence instead of a single number here\n                    d=50/60 , \n                    power=NULL)$power\n\n# now we can plot:\nplot(x=10:100 , \n     y=power, \n     type=\"o\", \n     xlab=\"Sample size (per group)\", \n     ylab=\"power (%)\")\n\n# add some gridlines because I like gridlines\ngrid()"
  },
  {
    "objectID": "solutions.html#exercise-8",
    "href": "solutions.html#exercise-8",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nMortality rates was 35% in the no treatment group.\nSuppose the smallest risk difference of interest is 10%. (this is up to you as investigator!)\n\n\n\nES.h(0.45, 0.35)\n\n[1] 0.2045252\n\n\nThis would correspond to an effect size of Cohorts H = 0.2\n\n\n\n\npwr.2p.test(h=0.2, n=NULL, power=0.8)\n\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2\n              n = 392.443\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n\n\nSo we would need 392 patients per group.\n\nSuppose we knew we could expect 200 patients per group. Then we would expect a minimum detectable effect size of:\n\n\npwr.2p.test(h=NULL, n=200, power=0.8)\n\n\n     Difference of proportion power calculation for binomial distribution (arcsine transformation) \n\n              h = 0.2801491\n              n = 200\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: same sample sizes\n\n\nSo the effect if 0.28, and the control rate is 35%, we can find the smallest detectable increase:\n\nES.h(.35 + 0.14, 0.35)\n\n[1] 0.2846913\n\n\nSo the smallest change detectable with 80% power is about 14%. If the expected increase in treatment effect is smaller than this then the study needs to be bigger."
  },
  {
    "objectID": "solutions.html#exercise-9",
    "href": "solutions.html#exercise-9",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nFor a paired t-test, we would use the type=\"paired\" option.\n\n\n\npwr.t.test(n=NULL, d = 20 / (sqrt(2)*30), power = 0.8 , type=\"paired\" )\n\n\n     Paired t test power calculation \n\n              n = 37.28621\n              d = 0.4714045\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nWe need ~40 participants, each of which will provide two measurements.\nIn the previous study, we would have needed 142 samples per group!\n\npwr.t.test(n=NULL, d = 20 / 60, power = 0.8  )\n\n\n     Two-sample t test power calculation \n\n              n = 142.2462\n              d = 0.3333333\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nSo pairing has helped a lot!\n\nLook at how the sample size depends on the critical threshold for p-value.\n\n\npwr.t.test(n=NULL, d = 20 / (sqrt(2)*30), power = 0.8 ,sig.level = 0.01, type=\"paired\" )\n\n\n     Paired t test power calculation \n\n              n = 55.90111\n              d = 0.4714045\n      sig.level = 0.01\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\npwr.t.test(n=NULL, d = 20 / (sqrt(2)*30), power = 0.8 ,sig.level = 0.001, type=\"paired\" )\n\n\n     Paired t test power calculation \n\n              n = 82.24009\n              d = 0.4714045\n      sig.level = 0.001\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*"
  },
  {
    "objectID": "solutions.html#exercise-10",
    "href": "solutions.html#exercise-10",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nDesign 1:\n\npwr.t.test(n=NULL , d=20/30, power=0.8)\n\n\n     Two-sample t test power calculation \n\n              n = 36.30569\n              d = 0.6666667\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\nDesign 2:\nChange in concentration will have sd:\n\nsd_change = sqrt(2) * sqrt(1-0.6) * 30\n\nSo the sample size needed is:\n\npwr.t.test(n=NULL , d=20/27, power=0.8)\n\n\n     Two-sample t test power calculation \n\n              n = 29.60082\n              d = 0.7407407\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nOnly slightly fewer than design 1\n\n\nDesign 3:\nGiven the ICC of 0.6, we would expect to explain 60% of variance by adjusting for the baseline value. We can use the Superpower R package to find how this affects the sample size needed, or adjust the standard deviation directly and use the regular pwr.t.test function:\n\nlibrary(Superpower)\n\nWarning: package 'Superpower' was built under R version 4.1.3\n\npower_oneway_ancova(mu=c(0,20),n=NULL,n_cov=1,sd=30,r2=0.6, alpha_level = 0.05, beta_level = 0.2)\n\n\n     Power Calculation for 1-way ANCOVA \n\n            dfs = 1, 29\n              N = 32\n              n = 16, 16\n          n_cov = 1\n             mu = 0, 20\n             sd = 30\n             r2 = 0.6\n    alpha_level = 0.05\n     beta_level = 0.1916029\n          power = 80.83971\n           type = exact\n\npwr.t.test(n=NULL, d=20 / (sqrt(0.4)*30), power=0.8)\n\n\n     Two-sample t test power calculation \n\n              n = 15.15109\n              d = 1.054093\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nThis suggests we only need 16 participants per group!\nSo this is a much more powerful approach than using the change score. How much sample size we can save depends on how well we can explain the outcome value with the baseline value, that is what is the ICC.\n\n\nDesign 4: Cross-over study\nWe saw in the last example that a cross-over trial where we use the same participant twice can be much more efficient:\n\npwr.t.test(n=NULL, d=20 / sd_change, power=0.8, type=\"paired\")\n\n\n     Paired t test power calculation \n\n              n = 16.15352\n              d = 0.745356\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nHere we would need 16 participants, but each would have to undergo two treatments and assessments. This might not be feasible."
  },
  {
    "objectID": "solutions.html#exercise-11",
    "href": "solutions.html#exercise-11",
    "title": "Solutions and notes for power and sample size course exercises",
    "section": "Exercise 11:",
    "text": "Exercise 11:\nTo power an ANOVA is a little more complicated, because the hypothesis is more complex. We have different effect sizes between different treatments, and we might be interested in the global p-value or in particular contrasts.\nThe assumptions for the power calculation will be the same as the assumptions for any ANOVA."
  },
  {
    "objectID": "posts/mysterybrot/index.html",
    "href": "posts/mysterybrot/index.html",
    "title": "Mysterybrot?",
    "section": "",
    "text": "Mandelbrot sets and mystery curves? Mysterybrots? Let’s go!"
  },
  {
    "objectID": "posts/mysterybrot/index.html#the-mandlebrot-set",
    "href": "posts/mysterybrot/index.html#the-mandlebrot-set",
    "title": "Mysterybrot?",
    "section": "The Mandlebrot set",
    "text": "The Mandlebrot set\nYou’ve all seen the the Mandlebrot set before. It’s one of the most familiar and iconic fractal images.\nIt was first produced around 1980 by Beniot Mandlebrot, based on mathematical work by Gaston Julia at the start of the 20th century. The fratcal is insanely beautiful and interesting, and as you all know if you have even the most passing interest in computer art, there are millions of beautiful images of it all over the place.\nThe formula underlying the Mandlebrot set is as simple as the outputs are complex. If we consider the sequence:\n\\[\\begin{align*}{}\nz_o&=0\\\\\nz_n&=z_{n-1}^2+c\n\\end{align*}\\]\nthen the Mandelbrot set includes all values \\(c\\in\\mathbb{C}\\) for which \\(z_n\\) does not diverge to infinity."
  },
  {
    "objectID": "posts/mysterybrot/index.html#mandlebrot-in-r",
    "href": "posts/mysterybrot/index.html#mandlebrot-in-r",
    "title": "Mysterybrot?",
    "section": "Mandlebrot in R",
    "text": "Mandlebrot in R\nGenerating images of the Mandlebrot set using R is very simple, given R’s natural handling of complex numbers and vectorisation.\nMyles Harrison has a nice explanation and code sample for a vectorised Mandelbrot set that survives as an R-bloggers post here: https://www.r-bloggers.com/2014/12/the-mandelbrot-set-in-r/. This is the output:"
  },
  {
    "objectID": "posts/mysterybrot/index.html#orbit-traps-vs-escape-times",
    "href": "posts/mysterybrot/index.html#orbit-traps-vs-escape-times",
    "title": "Mysterybrot?",
    "section": "Orbit traps vs escape times",
    "text": "Orbit traps vs escape times\nThe image above uses ‘escape time’ (k in the code) to colour the fractal. The escape time for each \\(c=x+iy\\) is the smallest \\(n\\) for which \\(|z_n|&gt;2\\). This leads to the discrete areas of colour in the image.\nAn alternative way to shade the fractal is by a so called ‘orbit trap’. The colour for each \\(c\\) is the closest \\(z_n\\) ever gets to a particular point or set of points in \\(\\mathbb{C}\\). Here I choose the origin as the reference point, so the colour in the image corresponds to \\(\\min(|z_n|)\\) for each \\(c\\).\n\nxmin = -2\nxmax = 2\nnx = 500\nymin = -1.5\nymax = 1.5\nny = 500\nn=200\n\n# variables\nx &lt;- seq(xmin, xmax, length.out=nx)\ny &lt;- seq(ymin, ymax, length.out=ny)\nc &lt;- outer(x,y*1i,FUN=\"+\")\nz &lt;- matrix(0.0, nrow=length(x), ncol=length(y))\no &lt;- matrix(1e5, nrow=length(x), ncol=length(y))\n\nfor (rep in 1:n) { \n    index &lt;- which(Mod(z) &lt; 2)\n    z[index] &lt;- z[index]^2 + c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index]))\n}\n\nimage(x,y,o^.2,col=hcl.colors(100,palette = \"Grays\"),asp=1)\n\n\n\n\n\n\n\n\nWe can make a couple of modifications to the visual display. Here I use a viridis palette, rescale the values with a log transformation and switch off the plotting annotations:\n\nl=1.5\n# variables\nres=1000\nn=100\nx &lt;- y &lt;- seq(-l,l, length.out=res)\nc &lt;- outer(x-.75,y*1i,FUN=\"+\")\nz &lt;- matrix(0.0, nrow=res, ncol=res)\no &lt;- matrix(1e5, nrow=res, ncol=res)\n\nfor (rep in 1:n) { \n    index &lt;- which(Mod(z) &lt; 2)\n    z[index] &lt;- z[index]^2 + c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index]))\n}\n\no2 &lt;- -log(o) |&gt; pmax(-6)\npar(mar=c(5,5,5,5))\nimage(x,y,o2,col=hcl.colors(500),asp=1,axes=F,ann=F)"
  },
  {
    "objectID": "posts/mysterybrot/index.html#multibrots",
    "href": "posts/mysterybrot/index.html#multibrots",
    "title": "Mysterybrot?",
    "section": "Multibrots!",
    "text": "Multibrots!\nUsing a higher power for the iteration equation leads to a related shape with a higher order of rotational symmetry. These are called multibrots. Pretty horrible word but there we are.\n\nl=1.5\n# variables\nres=1000\nn=100\npar(mfrow=c(2,2),mar=2*c(1,1,1,1))\nfor(i in c(3,4,5,6)){\n  x &lt;- y &lt;- seq(-l,l, length.out=res)\n  c &lt;- outer(x,y*1i,FUN=\"+\")\n  z &lt;- matrix(0.0, nrow=res, ncol=res)\n  o &lt;- matrix(1e5, nrow=res, ncol=res)\n  \n  for (rep in 1:n) { \n      #print(rep)\n      index &lt;- which(Mod(z) &lt; 2)\n      z[index] &lt;- z[index]^i + c[index]\n      o[index] &lt;- pmin(o[index] , Mod(z[index]))\n  }\n  o2 &lt;- -log(t(o)) |&gt; pmax(-10)\n  image(x,y,o2,col=hcl.colors(500,palette = hcl.pals(type=\"sequential\")[i]),asp=1,axes=F,ann=T,\n        main=bquote(z[n+1] == z[n]^.(i)+c), xlab = NULL, ylab=NULL)\n}"
  },
  {
    "objectID": "posts/mysterybrot/index.html#mysterybrots",
    "href": "posts/mysterybrot/index.html#mysterybrots",
    "title": "Mysterybrot?",
    "section": "Mysterybrots!",
    "text": "Mysterybrots!\nSo, what should be obvious from the image above is that the Multibrot of order \\(i\\) has order \\(i-1\\) rotational symmetry.\nSound familiar? It’s similar to the rule for a circular harmonograph.\n\nt &lt;- seq(0,2*pi,l=500)\npar(mfrow=c(2,2),mar=c(0,0,3,0))\nfor(i in 3:6){\n  plot(exp(1i*t) + exp(1i*t)^i, type=\"l\", axes=F,ann=T,xlab=\"\", ylab=\"\",asp=1,\n       main=sprintf(\"exp(2*pi*i*z) + exp(2*pi*i*z)^%d\",i))\n}\n\n\n\n\n\n\n\n\nThis is exciting because we know that we can make beautiful and interesting shapes (mystery curves) by adding circular harmonographs. So long as we choose the frequencies carefully. Eg here we add three circular movements, with frequencies 1, 4 and 7.\n\nt &lt;- seq(0,2*pi,l=500)\npar(mar=c(0,0,3,0))\nplot(exp(1i*t) + exp(1i*t)^4 + exp(1i*t)^7, \n     type=\"l\", axes=F,ann=T,xlab=\"\", ylab=\"\",asp=1,\n     main=sprintf(\"exp(2*pi*i*z) + exp(2*pi*i*z)^4 + exp(2*pi*i*z)^7\")\n     )\n\n\n\n\n\n\n\n\nIf we vary the amplitudes and the phases of the circular motion we can get all sorts of interesting shapes:\n\nset.seed(123)\nt &lt;- seq(0,2*pi,l=500)\npar(mfrow=c(3,3),mar=c(1,1,1,1),oma=c(1,1,1,1))\nfor(i in 1:9){\nplot(exp(1i*t) + runif(1)*exp(1i*t)^4 + runif(1)*exp(1i*(t+pi*runif(1)))^7, \n     type=\"l\", axes=F,ann=T,xlab=\"\", ylab=\"\",asp=1\n     )\n}\n\n\n\n\n\n\n\n\nNotice here every mystery curve has rotational symmetry order 3. This is because \\(1\\equiv 4\\equiv 7\\ \\pmod 3\\). In general, a mystery curve will have rotational symmetry order \\(k\\) if the frequency of each component is equivalent \\(\\pmod k\\).\nDoes the same thing happen if we add multibrots? What does it even mean to add multibrots? What happens if we use a more general polynomial in the iteration equation of the fractal, but keep the restriction that the order of each term should be equivalent to \\(1 \\pmod k\\).\nLets look at the fractal defined by the system:\n\\[\\begin{align*}{}\nz_o&=0\\\\\nz_n&=z_{n-1}^4+z_{n-1}^7+c\n\\end{align*}\\]\nand compare it to a similar mystery curve:\n\npar(mfrow=c(1,2))\npar(mar=c(0,0,3,0))\nl=1.5\n# variables\nres=1000\nn=100\nx &lt;- y &lt;- seq(-l,l, length.out=res)\nc &lt;- outer(x,y*1i,FUN=\"+\")\nz &lt;- matrix(0.0, nrow=res, ncol=res)\no &lt;- matrix(1e5, nrow=res, ncol=res)\nfor (rep in 1:n) { \n    #print(rep)\n    index &lt;- which(Mod(z) &lt; 2)\n    z[index] &lt;- \n          z[index]^4 +\n          z[index]^7 + \n          c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index]))\n}\no2 &lt;- -log(o) |&gt; pmax(-7)\nimage(x,y,o2,col=hcl.colors(1000,palette = \"Grays\"),asp=1,axes=F,ann=F,\n      main=\"bquote(z[n+1] == z[n]^.(i)+c)\")\n\nplot(exp(1i*t) + exp(1i*t)^4 + exp(1i*t)^7, \n     type=\"l\", axes=F,ann=T,xlab=\"\", ylab=\"\",asp=1, xlim=2*c(-l,l),ylim=2*c(-l,l),\n     main=sprintf(\"exp(2*pi*i*z) + exp(2*pi*i*z)^4 + exp(2*pi*i*z)^7\")\n     )\n\n\n\n\n\n\n\n\nSuccess! We have made a more general polynomial multibrot that has the same rotational symmetry as the mystery curve, and shows elements from each of its terms!\nI call these symmetric multibrots mysterybrots.\nHere’s some more:\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(0,0,0,0))\nl=1.5\n# variables\nres=1000\nn=100\nx &lt;- y &lt;- seq(-l,l, length.out=res)\nc &lt;- outer(x,y*1i,FUN=\"+\")\nz &lt;- matrix(0.0, nrow=res, ncol=res)\no &lt;- matrix(1e5, nrow=res, ncol=res)\nfor (rep in 1:n) { \n    #print(rep)\n    index &lt;- which(Mod(z) &lt; 2)\n    z[index] &lt;- \n          z[index]^4 -\n          z[index]^7 + \n          c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index]))\n}\no2 &lt;- -log(o)\nimage(x,y,o2,col=hcl.colors(1000),asp=1,axes=F,ann=F,\n      main= \"z = z^4-z^7 + c\")\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\npar(mar=c(0,0,0,0))\nl=1.5\n# variables\nres=1000\nn=100\nx &lt;- y &lt;- seq(-l,l, length.out=res)\nc &lt;- outer(x,y*1i,FUN=\"+\")\nz &lt;- matrix(0.0, nrow=res, ncol=res)\no &lt;- matrix(1e5, nrow=res, ncol=res)\nfor (rep in 1:n) { \n    #print(rep)\n    index &lt;- which(Mod(z) &lt; 2)\n    z[index] &lt;- \n          z[index]^6 -\n          (exp(2i*pi/3)*z[index])^11 + \n          c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index]))\n}\no2 &lt;- -log(o)\nimage(x,y,o2,col=hcl.colors(1000,palette = \"Oslo\"),asp=1,axes=F,ann=F)"
  },
  {
    "objectID": "posts/mysterybrot/index.html#animated-mysterybrot",
    "href": "posts/mysterybrot/index.html#animated-mysterybrot",
    "title": "Mysterybrot?",
    "section": "Animated mysterybrot",
    "text": "Animated mysterybrot\nBut wait, there’s more! By a similar process to that used in my mystery curve post, we can make beautiful animations by varying the mysterybrot parameters over time, ensuring continuous transitions between different multibrots of different orders, avoiding fractional orders that make messy images.\n(I can’t figure out how to get this to loop by default, do yourself a favour, right click and hit ‘loop’)\nVideo\nI love how the transitions between the multibrots of different orders work, with pieces of the fractal being tossed around and other parts rearranged as it evolves.\nThe key to the smooth transition between shapes of different orders is the same as in the mystery curves post, and it is explained there, but in short, the coefficients for terms in the polynomial used for iteration oscillate, and we only change the order of any of the terms when its coefficient is zero.\nThe complete code for this animation is below, but be warned, it takes ages to render this in R. It would probably work in real time using a shader, so if you want to reproduce this a shader is probably the better approach, unless you have a spare hour.\nThis code will create a .png for every frame of the animation, then you’ll need ffmpeg or similar to turn these into a video.\nThanks for reading, comments always welcome.\n\nfv &lt;- \\(x) ifelse(x &lt; 0.2 , x*3 , 1-(1-x)/2  ) # curve for the brightness\nres=1000 # resolution\nr=300  #  total number of frames\nfor(i in 1:r){\n  zoom=1.5\n  theta = 2*pi*i/r  # defines the amplitude of terms of the polynomial\n  a1 = cos(theta) * exp(-1i*theta)\n  a2 = (theta&lt;pi)*sin(theta) * exp(1i*2*theta)\n  a3 = (theta&gt;pi)*sin(theta) * exp(1i*2*theta)\n  x &lt;- zoom*seq(-1,1, l=res) # get the x and y axes\n  y &lt;- zoom*seq(-1,1, l=res) \n  c &lt;- outer(x,y*1i,FUN=\"+\")\n  z &lt;- matrix(0, nrow=res, ncol=res)\n  o &lt;- matrix(1e6 ,nrow=res, ncol=res)\n  k &lt;- matrix(0, nrow=res, ncol=res)\n  for (rep in 1:100) { # only need 100 reps\n    index &lt;- which(Mod(z) &lt; 10)\n    z[index] &lt;- \n      a1*z[index]^4 + \n      a2*z[index]^5 +\n      a3*z[index]^6 + \n      c[index]\n    o[index] &lt;- pmin(o[index] , Mod(z[index])^2)\n    \n  }\n\n  png(sprintf(\"mysterybrot%04d.png\",i), width=res,height=res, type=\"cairo\")\n  par(mfrow=c(1,1), mar=c(2,2,2,2), bg=\"#111111\")\n  if(i==1){ # set the breaks from the first frame to keep them consistent.\n    breaks &lt;- seq(-log(o)|&gt;pmax(-4) |&gt;min(),\n                  -log(o)|&gt;pmax(-4) |&gt;max(), \n                   l=501)\n  }\n  image(x,y,-log((o)) |&gt; pmax(-4),\n        col=hsv(seq(i/r+.0,i/r+0.8,l=500)%%1,seq(1,0,l=500),fv(seq(0,1,l=500))),\n        breaks=breaks, \n        asp=1,axes=F,ann=F, useRaster = TRUE)\n  dev.off()\n}\n\nshell(\"ffmpeg -r 30 -y -i mysterybrot%04d.png -c:v libx264 -r 30 -pix_fmt yuv420p mysterybrot.mp4\")"
  },
  {
    "objectID": "posts/lissajous/index.html",
    "href": "posts/lissajous/index.html",
    "title": "Lissajous curves",
    "section": "",
    "text": "This post describes one of my favourite pieces of creative coding. The process followed here is more-or-less the process by which I came to the final image, although there was a a lot more trial and error the first time around! The work is based around Lissajous curves, which are widely used in mathematical art and take their name from Jules Lissajous who extensively explored them in the 19th century.\nAn image search for ‘Lissajous art’ or similar will show you a lot of ways people have used Lissajous curves, or more generally harmonographs, to make beautiful images.\nHere’s the final output we’re aiming for in this post:"
  },
  {
    "objectID": "posts/lissajous/index.html#lissajous-curves",
    "href": "posts/lissajous/index.html#lissajous-curves",
    "title": "Lissajous curves",
    "section": "Lissajous curves",
    "text": "Lissajous curves\nLissajous curves are the shapes traced out by sinusoidal motion in two dimensions. They are characterised by the equations:\n\\[\\begin{align*}\nx & = A\\times\\sin(f_x t - \\delta_x) \\\\\ny & = B\\times\\cos(f_y t - \\delta_y) \\\\\n\\end{align*}\\]\nWhere \\(A\\) and \\(B\\) are amplitudes, \\(f_x\\) and \\(f_y\\) are the frequencies of the motion and \\(\\delta_x\\) and \\(\\delta_y\\) the phase shift.\nIt is simple to draw a Lissajous curve in R using:\n\nt = seq(0,10,0.01)\n\nx = sin(2*pi*t)\ny = cos(3*pi*t)\n\nplot(x,y,type=\"l\",asp=1)\n\n\n\n\n\n\n\n\nBy visualising the motion in both dimensions it should be clear how the shapes arise:\n\nt = seq(0,2,0.01)\nx = sin(2*pi*t)\ny = cos(6*pi*t)\nlimits = c(-1,1)\n\nfor(i in seq(0,2,l=100)){\n  plot(x,y,type=\"l\",asp=1,xlim=1.2*limits,ylim=1.2*limits)\n  lines(x=c(sin(2*i*pi),sin(2*i*pi),-1.1),\n        y=c(-1.1,cos(6*pi*i),cos(6*pi*i)),pch=20,type=\"o\",lty=\"dashed\")\n  }\n\n\n\n\n\n\n\n\nBy changing the frequencies we can generate some familiar shapes:\n\nfor(i in 1:4) for(j in 2:5){\n  plot(x = sin(i*pi*t),\n       y=cos(j*pi*t),\n       type=\"l\",asp=1,xlim=limits,ylim=limits,\n       main=sprintf(\"i=%d; j=%d\",i,j))\n}\n\n\n\n\n\n\n\n\nThere are lots of interesting things to do with Lissajous curves. Eg we can overlay lots of curves with different frequencies.\n\nplot(NA, xlim=limits,ylim=limits,asp=1)\nfor(i in 1:4) for(j in 2:5){\n  points(x = sin(i*pi*t),y=cos(j*pi*t),type=\"l\")\n}\n\n\n\n\n\n\n\n\nNow lets add a few more curves, think about how the colour and intensity should depend on the frequency, remove the axes and annotation etc. This image isn’t great but you can start to see how you’d make something interesting..\n\npar(mar=c(1,1,1,1))\nplot(NA, xlim=limits,ylim=limits,asp=1,axes=F,ann=F)\nfor(i in 1:10) for(j in -10:10){\n  points(x = sin(i*pi*t),\n         y = cos(j*pi*t),type=\"l\",\n         lwd=5/(abs(i-j)+2),\n         col=hsv(h=.5+j/20,\n         s=1/(abs(i-j)+2),\n         v=1-1/(abs(i-j)+2),\n         alpha=1/(abs(i-j)+2)))\n}\n\n\n\n\n\n\n\n\nWe can make the frequencies increase as a geometric rather than an arithmetic sequence. Here the \\(x\\) frequency is fixed at 5 and the \\(y\\) frequency varies from \\(2\\times 2^{-4}\\) to \\(2\\times 2^4\\). Again this output isn’t especially pretty but its the set of curves we ultimately use for the final output.\n\nt = seq(0,10,0.001)\npar(mar=c(1,1,1,1))\nlimits=c(-1,1)\nplot(NA, xlim=limits,ylim=limits,asp=1,axes=F,ann=F)\nfor(i in 5) for(a in (-4:4)){\n  points(x = sin(i*pi*t),\n         y = cos(2*2^a*pi*t),type=\"l\",\n         lwd=2,\n         col=hsv(h=.6,\n                 s=.5,v=.5,\n                 alpha=1/(abs(a)+1)))\n}\n\n\n\n\n\n\n\n\nNow for the part where we diverge from classic Lissajous curve shape.\nThe next image is the same as the previous one, except that I have replaced \\(x\\) with \\(x^3\\) and \\(y\\) with \\(y^3\\). I also swapped the \\(x\\) and \\(y\\) axes because the image looked nicer that way around.\nRaising the \\(x\\) and \\(y\\) positions to the third power retains the range of the curve but bunches up the curves along the axes and makes the shapes more interesting.\n\nt = seq(0,10,0.001)\npar(mar=c(1,1,1,1))\nlimits=c(-1,1)\nplot(NA, xlim=limits,ylim=limits,asp=1,axes=F,ann=F)\nfor(i in 5) for(a in (-4:4)){\n  points(y = sin(i*pi*t)^3,\n         x = cos(2*2^a*pi*t)^3,type=\"l\",\n         lwd=2,\n         col=hsv(h=.6,\n                 s=.5,v=.5,\n                 alpha=1/(abs(a)+1)))\n}\n\n\n\n\n\n\n\n\nThe other major innovation is to plot points of random sizes instead of lines, to create the textured effect in the final image.\nSomething else interesting happens when we switch to points instead of lines; since each path has the same number of points the shorter paths become denser so they are more prominent in the image:\n\nt = seq(0,50,l=1e4)\npar(mar=c(1,1,1,1))\nlimits=c(-1,1)\nplot(NA, xlim=limits,ylim=limits,asp=1,axes=F,ann=F)\nfor(i in 5) for(a in (-4:4)){\n  points(y = sin(i*pi*t)^3,\n         x = cos(2*2^a*pi*t)^3,type=\"p\",\n         cex=.5*runif(1000),\n         pch=20,\n         col=hsv(h=.6,\n                 s=runif(1000),v=runif(1000),\n                 alpha=runif(1000)/(abs(a)+1)))\n}\n\n\n\n\n\n\n\n\nThis is close to the final image! Tweaking some parameters can improve the balance between the curves, and lead us to something we are happy with.\nThe complete self-contained code for the final image is shown below.\nI have tweaked the point sizes a bit so they depend on which curve is being drawn, and used a normal distribution for the point sizes to get a longer tail of larger points.\nThe point hue is random, there is an off-white background and the number of points per curve is 30000. The frequency is always 5 in the \\(y\\) dimension, but varies from \\(2\\times 3^-4\\) to \\(2\\times 3^4\\) in the \\(x\\) dimension.\n\nset.seed(10072022)\nN=3e4\nt = seq(0,300,l=N)\npar(mar=2*c(1,1,1,1),bg=\"#fafafa\")\nlimits = c(-1,1)\n\nplot(NA, xlim=limits,ylim=limits,ax=F,an=F)\nfor(j in 2*3^(seq(-4,4,1))){\n  points(y = sin(5*pi*t)^3,\n         x = cos(j*pi*t)^3,\n         type=\"p\",\n         pch=20,\n         cex=rnorm(N)^1.0*.4*cos(t*pi/4+pi/3)+.05*(j==6)+.1*(j==2), # Random size\n         col=hsv(h=rnorm(N,.7,.1)%%1, # Random hue\n                 s=runif(N,0,1),      # Random saturation\n                 v=runif(N,0,1),      # Random value\n                 alpha=runif(N)))}    # Random alpha\n\n\n\n\n\n\n\n\nI am delighted with this image. The left and right panels make a lovely counterpoint to each other, as does the relationship between the two ‘major’ paths in each. The near-symmetry within each panel is an accident but I think it adds a lot to the final composition. ‘Cubing’ the Lissajous curves makes them familiar but not too familiar, in my opinion purely sinusoidal shapes can be a bit dull.\nThe intersections between paths are particularly pleasing, and the density and distribution of the points feels very organic. You could of course change the random number seed to get a different arrangement of sizes and colours.\nThe only thing I don’t like so much is the very high density of points in the dead centre of the image. I could try to artificially lighten this area but I don’t think that would help much. I also wonder if the overall colour and density is a little too uniform, but I can’t imagine how this could be improved."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Mysterybrot?\n\n\n\n\n\n\nart\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nGeorge\n\n\n\n\n\n\n\n\n\n\n\n\nFlow fields\n\n\n\n\n\n\nart\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 27, 2022\n\n\nGeorge\n\n\n\n\n\n\n\n\n\n\n\n\nLissajous curves\n\n\n\n\n\n\nart\n\n\nR\n\n\n\n\n\n\n\n\n\nJul 7, 2022\n\n\nGeorge\n\n\n\n\n\n\n\n\n\n\n\n\nMystery curves\n\n\n\n\n\n\nart\n\n\nR\n\n\n\n\n\n\n\n\n\nMay 2, 2022\n\n\nGeorge\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMay 2, 2022\n\n\nGeorge\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is my blog for creative coding."
  },
  {
    "objectID": "posts/flowfields/index.html",
    "href": "posts/flowfields/index.html",
    "title": "Flow fields",
    "section": "",
    "text": "Flow fields, or vector fields, are used a lot in generative art. Here I document an approach to using flow fields for art in R, leading to this image:\nI didn’t use field flows for ages as I wasn’t sure how I could add anything to what is already done, but lately I had a couple of ideas that seem innovative, or at least produce outputs that don’t look like anything else I’ve seen, so I think its worth documenting.\nSo I’ll demonstrate an approach creating flow fields using R, and then illustrate how they are used in my latest project."
  },
  {
    "objectID": "posts/flowfields/index.html#visualising-a-vector-field",
    "href": "posts/flowfields/index.html#visualising-a-vector-field",
    "title": "Flow fields",
    "section": "Visualising a vector field",
    "text": "Visualising a vector field\nAs with the mystery curves I use complex numbers, because this leads to some interesting maths in the 2D plane, and R makes working with complex numbers very natural.\nIn this first simple example I create a matrix of starting positions, \\(z\\), make a vector field \\(v\\) by rotating \\(z\\) position by just over 90 degrees to make a flow spiralling inward.\nDirection is measured by the argument of a complex number, and I want to keep the velocity of my flow constant, so I standardise \\(v\\) by diving by \\(\\left|v\\right|\\).\nFinally I increment the position using \\(z_{\\text{new}}=z+0.1\\times v\\) and draw arrows to the new points.\n\nset.seed(2911)\nlibrary(data.table)\n\nN=20\ndat &lt;- expand.grid(x=seq(-1,1,l=20), y=seq(-1,1,l=20))\nsetDT(dat)\n\ndat[ , z := x+1i*y ]  # represent positions as complex numbers\ndat[ , v := z*exp(1i*3*pi/5) ] # create vector field by rotating z by 3pi/5.\ndat[ , v := v/Mod(v) ]\n\ndat[ , znew := z + .1*v  ]\n\nplot(dat$z, pch=19)\narrows(Re(dat$z), Im(dat$z), Re(dat$znew), Im(dat$znew), length=0.05)"
  },
  {
    "objectID": "posts/flowfields/index.html#adding-streamlines",
    "href": "posts/flowfields/index.html#adding-streamlines",
    "title": "Flow fields",
    "section": "Adding streamlines",
    "text": "Adding streamlines\nStreamlines (following individual trajectories) are created by iterating the flow function. I’ll create a matrix called pos to store all the points along the streamlines for plotting. (In R maticies can be complex, each element is a complex number so keeps the \\(x\\) and \\(y\\) positions.)\n\n# N streamlines and m iterations\nN=20\nm=100\n\n# each row is a streamline\npos=matrix(nrow=N, ncol=m)\n\n# make random starting positions\nstartz = runif(N,-1,1) + 1i*runif(N,-1,1) \n\n# put these starting positions into the first column of pos.\npos[,1] &lt;- startz\n\n# now create the subsequent columns by iterating the equations above.\nfor(i in 2:m){\n  v &lt;- pos[,i-1]*exp(1i*3*pi/5)\n  pos[,i] &lt;- pos[,i-1] + .02 * v/Mod(v)\n}\n\nNow we can add the streamlines to the previous plot:\n\nplot(dat$z, pch=19,col=\"grey\")\narrows(Re(dat$z), Im(dat$z), Re(dat$znew), Im(dat$znew), length=0.05,col=\"grey\")\n\n#apply the `lines` function over the rows of pos to add the streams\napply(pos, 1, lines)\n\n\n\n\n\n\n\n\nNULL"
  },
  {
    "objectID": "posts/flowfields/index.html#rational-functions",
    "href": "posts/flowfields/index.html#rational-functions",
    "title": "Flow fields",
    "section": "Rational functions",
    "text": "Rational functions\nThe functions I’m going to use for my vector fields are rational functions, defined by the ratios of two polynomials. So our flow has modulus 1 and argument equal to the argument of:\nThat is, \\[f(z)=\\frac{\\prod_{i=1}^{n}(z-a_i)}{\\prod_{j=1}^{m}(z-b_j)}\\]\nI’ll illustrate this with a simple polynomial first, turning my last chunk into a function to plot a vector flow based on a function FUN, then passing it a simple polynomial:\n\n# takes a function and draws the vector field. \nplotFlow &lt;- function(FUN,col=\"black\") {\n\n  dat &lt;- expand.grid(x=seq(-1,1,l=20), y=seq(-1,1,l=20))\n  setDT(dat)\n  \n  dat[ , z := x+1i*y ]  # represent position as a complex number\n  dat[ , v := FUN(z) ]  # create vector field\n  dat[ , v := v/Mod(v) ]\n  dat[ , znew := z + .1*v  ]\n  plot(dat$z, pch=19,col=col)\n  arrows(Re(dat$z), Im(dat$z), Re(dat$znew), Im(dat$znew), length=0.05,col=col)\n}\n\nplotFlow( \\(z) (z-.5)*(z+.5)*z )\n\n\n\n\n\n\n\n\nNow we can just call this plotting function with whatever flow function we like. For example, lets plot the vectors associated with\n\\[f(z)=\\frac{z(z-0.5)(z+0.5)}{(z-0.5i+0.5)(z+0.5i-0.5)(z+0.1-0.1i)}\\]\n\nplotFlow( \\(z) (z-.5)*(z+.5)*z / ((z-0.5i+0.5)* (z+0.5i-0.5)*(z+.1-.1i)) )\n\n\n\n\n\n\n\n\nAdding streamlines as previously:\n\nflowFunction = \\(z) (z-.5)*(z+.5)*z / ((z-0.5i+0.5)* (z+0.5i-0.5)*(z+.1-.1i))\n\n# N streamlines and m iterations\n\nmakeStreams &lt;- function(startpos,m=200,FUN,d=0.02){\n  pos=matrix(nrow=N, ncol=m)\n  startz = runif(N,-1,1) + 1i*runif(N,-1,1)\n  pos[,1] &lt;- startz\n  for(i in 2:m){\n    v &lt;- FUN(pos[,i-1])\n    pos[,i] &lt;- pos[,i-1] + d * v/Mod(v)\n  }\n  pos\n}\n\nN=100\nstartZ &lt;- runif(N, -1,1) + 1i*runif(N, -1,1)\n\npos &lt;- makeStreams(startZ, FUN = flowFunction)\n\nplotFlow(flowFunction, col=\"grey\")\napply(pos, 1, lines)\n\n\n\n\n\n\n\n\nNULL\n\n\nSo we have a system for making field flow images. We define a function for our vector field, then pick starting points and iterate to create the subsequent paths.\nThe artistic elements now all come from how we choose the function and start positions, and how we draw the paths we create.\nIf we massively increase the number of paths but reduce the number of iterations:\n\nN=1000\nstartZ &lt;- runif(N, -1,1) + 1i*runif(N,-1,1)\npos &lt;- makeStreams(startZ,FUN=flowFunction,d=0.01)\nplot(NA, xlim=c(-1,1), ylim=c(-1,1))\napply(pos, 1, lines)\n\n\n\n\n\n\n\n\nNULL\n\n\nThis is a bit dense. If we just draw points instead of lines we can control the density a bit more, and we can use the scattermore library to speed up the plotting enormously:\n\nlibrary(scattermore)\npos &lt;- cbind(Re(as.vector(pos)), Im(as.vector(pos)))\nscattermoreplot(pos,size=c(800,600), xlim=c(-1,1), ylim=c(-1,1))\n\n\n\n\n\n\n\n\nBefore we go any further, lets have a look at the implications of choosing specific roots for the polynomials in our rational function. The numerator here has roots at \\(0.5\\), \\(-0.5\\) and \\(0\\). The denominator’s root are at \\(-0.5+0.5i\\), \\(0.5-0.5i\\), and \\(-0.1+0.1i\\). Lets add these points onto the graph to see how they interact with the flow:\n\nscattermoreplot(pos,size=c(800,600), xlim=c(-1,1), ylim=c(-1,1))\npoints(c(-0.5+0.5i, 0.5-0.5i,-0.1+0.1i), col=\"blue\", cex=2,pch=4, lwd=4)\npoints(c(-0.5+0i, 0.5,0), col=\"red\", cex=2,pch=1, lwd=4)\n\n\n\n\n\n\n\n\nIt seems at least in this case that the roots of the numerator (red dots) represent sinks or sources for the flow, that is points where flows are either attracted to or repelled from. The roots of the denominator (the poles of the rational function; blue crosses) are saddle points, flows are attracted to them on one axis but repelled in others, hence flows appear to ‘miss’ them altogether.\nIn fact, this property generally holds, the zeros of our rational function will be sinks or sources, whereas the poles will be saddle points. We can prove this by noting that the argument of our rational function will be the sum of the arguments of the respective terms, and by thinking about how this sum changes as we move around a small area close to one of the poles or zeros.\nIn our image so far paths are starting from their randomly generated positions, and then flowing toward a sink or off the page. I think this looks messy, I would rather include the entire flow lines, and so I will add the flows both forwards and backwards from each start point. This way I generate the entire flow passing through each point, rather than just a random portion of it.\nI’m also changing the makeStreams function to return two column matrix of x and y positions in the form that scattermoreplot expects.\n\nmakeStreams &lt;- function(startpos,m=100,FUN,d=0.1){\n  pos=matrix(nrow=length(startpos), ncol=m)\n  pos2=matrix(nrow=length(startpos), ncol=m)\n  pos[,1] &lt;- startpos\n  pos2[,m] &lt;- startpos\n  for(i in 2:m){\n    v &lt;- FUN(pos[,i-1])\n    pos[,i] &lt;- pos[,i-1] + d * v/Mod(v)\n  }\n  for(i in (m-1):1){\n    v &lt;- FUN(pos2[,i+1])\n    pos2[,i] &lt;- pos2[,i+1] - d * v/Mod(v)\n  }\n  pos &lt;-cbind(pos,pos2) |&gt; as.vector()\n  cbind(Re(pos),Im(pos))\n}\n\npos &lt;- makeStreams(startZ, FUN=flowFunction,d=0.01)\n\nscattermoreplot(pos,size=c(1000,1000), xlim=c(-1,1), ylim=c(-1,1))\n\n\n\n\n\n\n\n\nWe can make a couple of easy improvements. First by squaring the aspect ratio of the plot, second by altering the spacing between the points. At the moment it is fixed, leading to some unintended patterns in the plot points, but we can easily set it to be random:\n\nmakeStreams &lt;- function(startpos,m=100,FUN,d=0.1){\n  N=length(startpos)\n  pos=matrix(nrow=N, ncol=m)\n  pos2=matrix(nrow=N, ncol=m)\n  pos[,1] &lt;- startpos\n  pos2[,m] &lt;- startpos\n  for(i in 2:m){\n    v &lt;- FUN(pos[,i-1])\n    pos[,i] &lt;- pos[,i-1] + runif(N,0,2)*d * v/Mod(v)\n  }\n  for(i in (m-1):1){\n    v &lt;- FUN(pos2[,i+1])\n    pos2[,i] &lt;- pos2[,i+1] - runif(N,0,2)*d* v/Mod(v)\n  }\n  pos &lt;-cbind(pos,pos2) |&gt; as.vector()\n  cbind(Re(pos),Im(pos))\n}\n\npos &lt;- makeStreams(startZ, FUN=flowFunction,d=0.01)\n\npar(mar=c(1,1,1,1))\nscattermoreplot(pos, size=c(1000,1000),xlim=c(-1,1), ylim=c(-1,1),asp=1,col=hsv(0,0,0,.5))"
  },
  {
    "objectID": "posts/flowfields/index.html#more-complex-flow-functions",
    "href": "posts/flowfields/index.html#more-complex-flow-functions",
    "title": "Flow fields",
    "section": "More complex flow functions",
    "text": "More complex flow functions\nThis image isn’t particularly appealing, but now that we have this system we can make a lot of beautiful images just choosing the locations of the poles and zeros of our flow function, the starting points of the flows and how they are rendered.\nFirst, lets add some more poles and zeros to our flow function. Our original function had three poles and three zeros. Here I’m going to add 20 poles and 20 zeros, choosing the location of each randomly within the canvas.\n\n# Choose the location of the poles and zeros\npoles &lt;- runif(20,-1,1) + 1i*runif(20,-1,1)\nzeros &lt;- runif(20,-1,1) + 1i*runif(20,-1,1)\n\n# Our flow function\nflowFunction &lt;- function(z) {\n  fz = z-zeros[1]\n  for(i in zeros[-1]) fz = fz * (z-i)\n  for(i in poles) fz = fz / (z-i)\n  fz/Mod(fz)\n  }\n\n# Make the streams positions\npos &lt;- makeStreams(startZ,m=500,FUN=flowFunction,d=0.002)\n\n# Plot\npar(mar=c(1,1,1,1))\nscattermoreplot(pos,size=c(1000,1000), xlim=c(-1,1), ylim=c(-1,1),asp=1,axes=F)\n\n\n\n\n\n\n\n\n\nChoosing which streamlines to plot by setting the starting points\nNext lets alter the starting positions of the flows. In the image above they are randomly selected throughout the canvas, but I could instead start them in a ring of radius 0.5 around the canvas centre. So here we’re seeing every streamline that passes through that ring.\nThe number of poles and zeros is also reduced.\n\nstartZ &lt;- 0.6*exp(2i * pi * seq(0,1,l=300))\n\nset.seed(123)\npoles &lt;- runif(5,-1,1) + 1i*runif(5,-1,1)\nzeros &lt;- runif(10,-1,1) + 1i*runif(10,-1,1)\n\npos &lt;- makeStreams(startZ,m=1000,FUN=flowFunction,d=0.002)\n\npar(mar=c(1,1,1,1))\nscattermoreplot(pos,size=c(1000,1000), xlim=c(-1,1), ylim=c(-1,1),asp=1,axes=F,col=hsv(0,0,0))\n\n\n\n\n\n\n\n\nNext exactly the same flow field but with many more streamlines (10000 vs 300) but each with fewer points included creates an effect that looks more like shading:\n\nstartZ &lt;- 0.6*exp(2i * pi * seq(0,1,l=10000))\npos &lt;- makeStreams(startZ,m=200,FUN=flowFunction,d=0.005)\npar(mar=c(1,1,1,1))\nscattermoreplot(pos,size=c(3000,3000), xlim=c(-1,1), ylim=c(-1,1),asp=1,axes=F,col=hsv(0,0,0))\n\n\n\n\n\n\n\n\nOr we could start them at random points along a line passing through the origin:\n\nN=5000\n\nstartZ &lt;- runif(N,-1,1)*(1 + 1i*runif(1,-.5,.5))\n\npos &lt;- makeStreams(startZ,m=200,FUN=flowFunction,d=0.01)\n\npar(mar=c(1,1,1,1))\nscattermoreplot(pos,size=c(2000,2000), xlim=c(-1,1), ylim=c(-1,1),asp=1,axes=F)\n\n\n\n\n\n\n\n\n\n\nChoosing locations for the poles and zeros\nHere I add 10 poles and 20 zeros arranges in a circle with radius 0.5.\n\npoles &lt;- exp(2i*pi*runif(5))*0.3\nzeros &lt;- exp(2i*pi*runif(10))*0.3\n\nstartZ = runif(10000, -1,1) + 1i*runif(10000,-1,1)\n\npos &lt;- makeStreams(startZ,m=500,FUN=flowFunction,d=0.001)\n\npar(mar=c(1,1,1,1))\nscattermoreplot(pos,size=c(3000,3000),xlim=c(-1,1), ylim=c(-1,1),axes=F,\n                col=hsv(0,0,0,.5))"
  },
  {
    "objectID": "posts/flowfields/index.html#a-few-more-examples",
    "href": "posts/flowfields/index.html#a-few-more-examples",
    "title": "Flow fields",
    "section": "A few more examples",
    "text": "A few more examples\nFinally I’ll show a few more examples of different outputs from this system. Most have an element of randomness since the locations of the poles and zeros are selected randomly. Rerunning the code, or changing the seed where it is set, will lead to a different image.\nWhite on black works quite well.\n\npoles &lt;- exp(2i*pi*runif(10))*0.4\nzeros &lt;- exp(2i*pi*runif(20))*0.4\n\nstartZ &lt;- 0.7*exp(2i * pi * seq(0,1,l=20000))\npos &lt;- makeStreams(startZ,m=300,FUN=flowFunction,d=0.01)\n\n  par(mar=c(1,1,1,1), bg=\"#111111\")\n  scattermoreplot(pos, \n                size=c(1800,1800),\n                xlim=c(-1,1), \n                ylim=c(-1,1), \n                col=hsv(1,0,1,.1),\n                axes=F)\n\n\n\n\n\n\n\n\nI’ve left the ring of starting points visible on the image because I think it looks nice, but you could easily modify the makeStreams function to remove the starting points from the pos matrix.\nFor the next image, two concentric circles of starting points, one inside and one outside the ring of poles and zeros:\n\nset.seed(1214)\npolesandzeros &lt;- .5*exp(2i*pi*seq(0,1,l=50)[-1])\npole = rbinom(20, 1,0.6)\npoles = polesandzeros[pole==1]\nzeros = polesandzeros[pole==0]\n\nN=20000\nstartZ &lt;- c(\n  0.3*exp(2i * pi * seq(0,1,l=N/2)),\n  0.7*exp(2i * pi * seq(0,1,l=N/2))\n  )\n\npos &lt;- makeStreams(startZ,m=300,FUN=flowFunction,d=0.01)\n\n  par(mar=0*c(1,1,1,1), bg=\"#111111\")\n  scattermoreplot(pos, \n                size=c(1800,1800),\n                xlim=c(-1,1), \n                ylim=c(-1,1), \n                col=hsv(1,0,1,.1),\n                axes=F)\n\n\n\n\n\n\n\n\nThe poles and zeros can be arranged along a polynomial, with four different circles providing starting positions for the flows.\nThe colour is fixed within each streamline but the saturation varies between them.\nFour circles provide starting points:\n\nset.seed(1214)\npolesandzeros &lt;- .5*exp(2i*pi*seq(0,1,l=40)[-1])\npolesandzeros &lt;- seq(-1,1,l=40)-0.5i*seq(-1,1,l=40) + .7i*seq(-1,1,l=40)^2 - .3i\npole = rbinom(39, 1,0.6)\npoles = polesandzeros[pole==1]\nzeros = polesandzeros[pole==0]\n\nstartZ &lt;- c(\n  0.3*exp(2i * pi * seq(0,1,l=N/4))-0.3-0.3i,\n  0.2*exp(2i * pi * seq(0,1,l=N/4))+0.3-0.3i,\n  0.15*exp(2i * pi * seq(0,1,l=N/4))-0.6+0.6i,\n  0.5*exp(2i * pi * seq(0,1,l=N/4))+0.3+0.3i\n  )\n  \npos &lt;- makeStreams(startZ,m=300,FUN=flowFunction,d=0.01)\n\npar(mar=0*c(1,1,1,1), bg=\"#111111\")\nscattermoreplot(pos,size=c(1800,1800),\n                xlim=c(-1,1), \n                ylim=c(-1,1), \n                col=hsv(0,rep(seq(0,1,l=N/4),4*600),1,0.1),\n                axes=F)\n\n\n\n\n\n\n\n\nNow here’s the code for the cover image for this post.\nThe poles and zeros are set along the same polynomial as in the previous example. The starting points are arranged in six concentric circles, and the streamlines from each have a different colour between red and blue.\n\nset.seed(1211)\n\npolesandzeros &lt;- seq(-1,1,l=40)-0.5i*seq(-1,1,l=40) + .7i*seq(-1,1,l=40)^2 - .3i\n\npole = rbinom(39, 1,0.5)\npoles = polesandzeros[pole==1]\nzeros = polesandzeros[pole==0]\n\nN=60000\nstartZ &lt;- c(\n  0.5*exp(2i * pi * seq(0,1,l=N/6)),\n  0.3*exp(2i * pi * seq(0,1,l=N/6)),\n  0.4*exp(2i * pi * seq(0,1,l=N/6)),\n  0.6*exp(2i * pi * seq(0,1,l=N/6)),\n  0.8*exp(2i * pi * seq(0,1,l=N/6)),\n  1.0*exp(2i * pi * seq(0,1,l=N/6))\n  )\n  \npos &lt;- makeStreams(startZ,m=500,FUN=flowFunction,d=0.005)\n\ncol=rep(c(hsv(0,  1,0.5,0.4),\n          hsv(0.0,1,0.5,0.4),\n          hsv(0.1,1,0.5,0.4),\n          hsv(0.9,1,0.5,0.4),\n          hsv(0.8,1,0.5,0.4),\n          hsv(1,  1,0.5,0.1)\n          ), each=N/6)\ncol &lt;- rep(col,1000)\n\npar(mar=0.1*c(1,1,1,1), bg=\"#dddddd\")\nscattermoreplot(pos,size=c(3000,3000),\n                xlim=c(-1,1), \n                ylim=c(-1,1), \n                col=col,\n                axes=F)"
  },
  {
    "objectID": "posts/flowfields/index.html#a-few-more-nice-outputs",
    "href": "posts/flowfields/index.html#a-few-more-nice-outputs",
    "title": "Flow fields",
    "section": "A few more nice outputs",
    "text": "A few more nice outputs\nThese are selected from randomly generated images based on the system described above, with various combinations of starting points and rational flow functions."
  },
  {
    "objectID": "posts/mystery/index.html",
    "href": "posts/mystery/index.html",
    "title": "Mystery curves",
    "section": "",
    "text": "‘Mystery curves’ are described by Frank Farris in his book Creating Symmetry. They are a kind of circular harmonograph, each created by summing three circular components, and are the basis for a lot of my creative coding.\nFor example, these two pieces are both based on mystery curves:\nIn this post I’ll explain how mystery curves are put together, how I do this using R, and finish with the complete code of an animation."
  },
  {
    "objectID": "posts/mystery/index.html#artistic-augmentations",
    "href": "posts/mystery/index.html#artistic-augmentations",
    "title": "Mystery curves",
    "section": "Artistic augmentations",
    "text": "Artistic augmentations\nNow there’s a few things we would want to change about this plot. We don’t want the axes or the annotation, we would like it to be a connected as a line rather than a series of points, and we would like the aspect ratio to be 1. I also set and the linewidth lwd to be 2.\nSo we can amend our script as follows:\n\nt = seq(0, 4, l=1000)\nz = 1i^t\nplot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)"
  },
  {
    "objectID": "posts/mystery/index.html#a-mystery-curve",
    "href": "posts/mystery/index.html#a-mystery-curve",
    "title": "Mystery curves",
    "section": "A mystery curve",
    "text": "A mystery curve\nNow to add the mystery elements. These are created by adding more circular motion with different amplitude, frequency and phase to our existing circle. For example, lets plot \\(z(t)=i^t + 0.5i^{5t+1}\\).\n\namp=0.5\nfreq=5\nphase=1\n\nz = 1i^t +                      # Our original circle\n  amp*(1i^(freq*t + phase))     # A new cirlce\n\nplot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)\n\n\n\n\n\n\n\n\nThe animation below shows how this curve works. We are adding two circular motions together, the second rotating five times for every one rotation of the first, but with a smaller radius (0.5) and starting from a different angle. Notice how the second circle rotating five times for every one of the main circle leads to 4-fold rotational symmetry in the resulting shape:\n\namp=0.5\nfreq=5\nphase=1\nt = seq(0, 4, l=1000)\n\nfor(j in seq(1,1000,10)){\n\n      z = 1i^t +                        # Our original circle\n          amp*(1i^(freq*t + phase))     # A new cirlce\n      \n      plot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)\n\n      lines(c(0,(1i^t)[j],z[j]),lwd=3,col=\"red\") # add lines\n      points(c(0,(1i^t)[j],z[j]),cex=2,pch=20)   # add points\n\n      }\n\n\n\n\n\n\n\n\nNow when we add another term we get a plot that looks even more interesting. Rather than defining \\(t\\) and typing out the formula for a circle each time, I will create a function to define a circle, then add three circles together as follows:\n\ncircle &lt;- function(amp, freq, phase) amp*1i^(freq*seq(0,4,l=1000)+phase)\n\nz = circle(1,1,0) + circle(0.5,5,0) + circle(0.6,9,1)\n\nplot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)\n\n\n\n\n\n\n\n\nWe can animate the motion similarly to the previous curve:\n\ncircle &lt;- function(amp, freq, phase) amp*1i^(freq*seq(0,4,l=1000)+phase)\n\nfor(j in seq(1,1000,2)){\n\n      z = circle(1,1,0) + circle(0.5,5,0) + circle(0.6,9,1)\n      plot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)\n      lps = cumsum(c(0,circle(1,1,0)[j],circle(0.5,5,0)[j],circle(0.6,9,1)[j]))\n      lines(lps,lwd=3,col=\"red\")\n      points(lps,cex=2,pch=20)\n      }\n\n\n\n\n\n\n\n\nNote that this plot, with three components having frequencies 1, 5 and 9 still has 4-fold rotational symmetry. As Farris explains, the image will have \\(N\\)-fold rotational symmetry if the frequency of each circle has the same remainder when divided by \\(N\\), that is, all frequencies equal mod \\(N\\). Here, 1, 5 and 9 are all 1 (mod 4) and so the image has 4-fold rotational symmetry.\nWe can include negative frequencies as well, so long as we remember this rule. Since \\(-7\\mod 4 =1\\) this will also have 4-fold rotational symmetry:\n\ncircle &lt;- function(amp, freq, phase) amp*1i^(freq*seq(0,4,l=1000)+phase)\n\nfor(j in seq(1,1000,2)){\n      z = circle(1,1,0) + circle(0.5,5,0) + circle(0.6,-7,1)\n      plot(z, axes=FALSE, ann=FALSE, type=\"l\", lwd=2, asp=1)\n      \n      lps = cumsum(c(0,circle(1,1,0)[j],circle(0.5,5,0)[j],circle(0.6,-7,1)[j]))\n      lines(lps,lwd=3,col=\"red\")\n      points(lps,cex=2,pch=20)\n}\n\n\n\n\n\n\n\n\nWe can alter the shape of a curve over time by changing its parameters as we animate. In the code below, an animation is built with the parameter \\(j\\) which varies from 0 to 4 in 100 steps . The phase shift (starting angle) of the third component is set equal to \\(j\\).\nIn addition, the limits of the plot are now fixed at \\((-2,2)\\) in both dimensions.\n\ncircle &lt;- function(amp, freq, phase) amp*1i^(freq*seq(0,4,l=1000)+phase)\nlimits=c(-1,1)*2\n\nfor( j in seq(0,4,l=100)[-1]){\n\n      z = circle(1,1,0) + circle(0.5,5,0) + circle(0.6,-7,j)\n      \n      plot(z, xlim=limits, ylim=limits,\n           axes=FALSE, ann=FALSE, type=\"l\", \n           lwd=2, asp=1, mar=c(0,0,0,0))\n      }"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome to my Creative Coding blog.\nFor the past few years I’ve been making pretty things with code.\nI’ve discovered a few tricks along the way, and the aim of this blog is to share these with the community.\nI have learnt a lot from others blog posts, and so with this site hope to give something back.\nMy main language for coding is R, although I hope that the posts will be useful for those using other languages.\nMy instagram is linked from the navbar above, if there’s something there you’d like me to write about, then get it touch!"
  }
]